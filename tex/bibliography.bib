%
%  An example of a bibliographical database for bibTeX
%
%  Recommended software for maintenance of *.bib files:
%    JabRef, http://jabref.sourceforge.net/
%
%  BEWARE:
%
%    *  If a name contains a capital letter, which must be kept such,
%       use curly brackets ({T}hailand, {HIV}).
%
%  ===========================================================================

@InProceedings{Andre2014,
  Title                    = {Coordinated Multi-Robot Exploration: Out of the Box Packages for {ROS}},
  Author                   = {Andre, T. and Neuhold, D. and Bettstetter, C.},
  Booktitle                = {Proc. of IEEE GLOBECOM WiUAV Workshop},
  Year                     = {2014},
  Month                    = dec,
}

@misc{MapstitchROS,
  author = {Philipp M. Scholl},
  journal = {ROS Wiki},
  title = {Mapstitch},
  publisher = {Open Source Robotics Foundation},
  address = {Mountain View, CA},
  URL = {http://wiki.ros.org/mapstitch},
  year="2012",
}

@Article{Brown2006,
author="Brown, Matthew
and Lowe, David G.",
title="Automatic Panoramic Image Stitching using Invariant Features",
journal="International Journal of Computer Vision",
year="2006",
volume="74",
number="1",
pages="59--73",
abstract="This paper concerns the problem of fully automated panoramic image stitching. Though the 1D problem (single axis of rotation) is well studied, 2D or multi-row stitching is more difficult. Previous approaches have used human input or restrictions on the image sequence in order to establish matching images. In this work, we formulate stitching as a multi-image matching problem, and use invariant local features to find matches between all of the images. Because of this our method is insensitive to the ordering, orientation, scale and illumination of the input images. It is also insensitive to noise images that are not part of a panorama, and can recognise multiple panoramas in an unordered image dataset. In addition to providing more detail, this paper extends our previous work in the area (Brown and Lowe, 2003) by introducing gain compensation and automatic straightening steps.",
issn="1573-1405",
doi="10.1007/s11263-006-0002-3",
url="http://dx.doi.org/10.1007/s11263-006-0002-3"
}

@TechReport {Szeliski2004,
abstract     = {This tutorial reviews image alignment and image stitching algorithms. Image
                alignment (registration) algorithms can discover the large-scale (parametric)
                correspondence relationships among images with varying degrees of overlap. They
                are ideally suited for applications such as video stabilization, summarization,
                and the creation of large-scale panoramic photographs. Image stitching algorithms
                take the alignment estimates produced by such registration algorithms and blend
                the images in a seamless manner, taking care to deal with potential problems such
                as blurring or ghosting caused by parallax and scene movement as well as varying
                image exposures. This tutorial reviews the basic motion models underlying
                alignment and stitching algorithms, describes effective direct (pixel-based) and
                feature-based alignment algorithms, and describes blending algorithms used to
                produce seamless mosaics. It closes with a discussion of open research problems
                in the area.},
author       = {Richard Szeliski},
institution  = {Microsoft Research},
month        = {October},
number       = {MSR-TR-2004-92},
pages        = {89},
title        = {Image Alignment and Stitching: A Tutorial},
url          = {http://research.microsoft.com/apps/pubs/default.aspx?id=70092},
year         = {2004},
}

@Inproceedings {Shum1998,
abstract     = {This paper presents a new approach to computing depth maps from a large
                collection of images where the camera motion has been constrained to planar
                concentric circles. We resample the resulting collection of regular perspective
                images into a set of multiperspective panoramas, and then compute depth maps
                directly from these resampled images. Only a small number of multiperspective
                panoramas is needed to obtain a dense and accurate 3D reconstruction, since our
                panoramas sample uniformly in three dimensions: rotation angle, inverse radial
                distance, and vertical elevation. Using multiperspective panoramas avoids the
                limited overlap between the original input images that causes problems in
                conventional multi-baseline stereo. Our approach differs from stereo matching of
                panoramic images taken from different locations, where the epipolar constraints
                are sine curves. For our multiperspective panoramas, the epipolar geometry, to
                first order, consists of horizontal lines. Therefore, any traditional stereo
                algorithm can be applied to multiperspective panoramas without modification.
                Experimental results show that our approach generates good depth maps that can be
                used for image-based rendering tasks such as view interpolation and
                extrapolation.},
address      = {Bombay},
author       = {Heung-Yeung Shum and Richard Szeliski},
booktitle    = {Sixth International Conference on Computer Vision (ICCV'98)},
month        = {January},
pages        = {953-958},
publisher    = {IEEE Computer Society},
title        = {Construction and refinement of panoramic mosaics with global and local alignment},
url          = {http://research.microsoft.com/apps/pubs/default.aspx?id=75611},
year         = {1998},
}

@INPROCEEDINGS{Rublee2011,
author={E. Rublee and V. Rabaud and K. Konolige and G. Bradski},
booktitle={2011 International Conference on Computer Vision},
title={ORB: An efficient alternative to SIFT or SURF},
year={2011},
pages={2564-2571},
abstract={Feature matching is at the base of many computer vision problems, such as object recognition or structure from motion. Current methods rely on costly descriptors for detection and matching. In this paper, we propose a very fast binary descriptor based on BRIEF, called ORB, which is rotation invariant and resistant to noise. We demonstrate through experiments how ORB is at two orders of magnitude faster than SIFT, while performing as well in many situations. The efficiency is tested on several real-world applications, including object detection and patch-tracking on a smart phone.},
keywords={computer vision;image matching;object detection;object recognition;tracking;transforms;BRIEF;ORB;SIFT;SURF;binary descriptor;computer vision;feature matching;noise resistance;object detection;object recognition;patch-tracking;smart phone;Boats},
doi={10.1109/ICCV.2011.6126544},
ISSN={1550-5499},
month={Nov},
}

@Article{Xie2015,
author="Xie, Xin
and Xu, Yin
and Liu, Qing
and Hu, Fengping
and Cai, Tijian
and Jiang, Nan
and Xiong, Huandong",
title="A study on fast SIFT image mosaic algorithm based on compressed sensing and wavelet transform",
journal="Journal of Ambient Intelligence and Humanized Computing",
year="2015",
volume="6",
number="6",
pages="835--843",
abstract="Considering the disadvantages of massive calculation and slow speed of traditional Scale Invariant Feature Transform (SIFT) algorithm, we propose an improved image mosaic method which combines Wavelet Transform (WT) and Compressed Sensing (CS) algorithm. The method works as follows. Firstly, images are transformed with wavelet and compressed using compressed sensing technology. Then, image feature points are extracted in combination with SIFT algorithm. Finally, Sequential Similarity Detection Algorithm (SSDA) with adaptive threshold is used to fast search of image matching to find out an optimal stitching line, and a panoramic image is obtained. Experimental results demonstrate that the method realizes fast image matching, efficiently overcomes the shortcomings of heavy computation and low efficiency in the process of extracting image features, and guarantees matching accuracy and stitching efficiency, which meets the real-time requestments in machine vision system. This algorithm can be applied to image matching and stitching in the field of digital image security.",
issn="1868-5145",
doi="10.1007/s12652-015-0319-2",
url="http://dx.doi.org/10.1007/s12652-015-0319-2"
}

@misc{lowe2004method,
  title={Method and apparatus for identifying scale invariant features in an image and use of same for locating an object in an image},
  author={Lowe, D.G.},
  url={http://www.google.com/patents/US6711293},
  year={2004},
  month=mar # "~23",
  publisher={Google Patents},
  note={US Patent 6,711,293}
}

@INPROCEEDINGS{Alahi2012,
author={A. Alahi and R. Ortiz and P. Vandergheynst},
booktitle={Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on},
title={FREAK: Fast Retina Keypoint},
year={2012},
pages={510-517},
abstract={A large number of vision applications rely on matching keypoints across images. The last decade featured an arms-race towards faster and more robust keypoints and association algorithms: Scale Invariant Feature Transform (SIFT)[17], Speed-up Robust Feature (SURF)[4], and more recently Binary Robust Invariant Scalable Keypoints (BRISK)[I6] to name a few. These days, the deployment of vision algorithms on smart phones and embedded devices with low memory and computation complexity has even upped the ante: the goal is to make descriptors faster to compute, more compact while remaining robust to scale, rotation and noise. To best address the current requirements, we propose a novel keypoint descriptor inspired by the human visual system and more precisely the retina, coined Fast Retina Keypoint (FREAK). A cascade of binary strings is computed by efficiently comparing image intensities over a retinal sampling pattern. Our experiments show that FREAKs are in general faster to compute with lower memory load and also more robust than SIFT, SURF or BRISK. They are thus competitive alternatives to existing keypoints in particular for embedded applications.},
keywords={computational complexity;eye;image matching;smart phones;transforms;SIFT;SURF;association algorithm;binary robust invariant scalable keypoint;binary string;computation complexity;embedded application;embedded device;fast retina keypoint;human visual system;keypoint descriptor;keypoint matching;scale invariant feature transform;smart phone;speed-up robust feature;vision application;Detectors;Humans;Kernel;Noise;Retina;Robustness;Vectors},
doi={10.1109/CVPR.2012.6247715},
ISSN={1063-6919},
month={June},}

@article{alcantarilla2011fast,
  title={Fast explicit diffusion for accelerated features in nonlinear scale spaces},
  author={Alcantarilla, Pablo F and Solutions, TrueVision},
  journal={IEEE Trans. Patt. Anal. Mach. Intell},
  volume={34},
  number={7},
  pages={1281--1298},
  year={2011}
}

@article{calonder2010brief,
  title={Brief: Binary robust independent elementary features},
  author={Calonder, Michael and Lepetit, Vincent and Strecha, Christoph and Fua, Pascal},
  journal={Computer Vision--ECCV 2010},
  pages={778--792},
  year={2010},
  publisher={Springer}
}

@inproceedings{Muja2012,
  author    = {Marius Muja and David G. Lowe},
  title = {Fast Matching of Binary Features},
  booktitle = {Computer and Robot Vision {(CRV)}},
  year = {2012},
  pages = {404-410}
}

@article{fischler1981random,
  title={Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography},
  author={Fischler, Martin A and Bolles, Robert C},
  journal={Communications of the ACM},
  volume={24},
  number={6},
  pages={381--395},
  year={1981},
  publisher={ACM}
}
