%
%  An example of a bibliographical database for bibTeX
%
%  Recommended software for maintenance of *.bib files:
%    JabRef, http://jabref.sourceforge.net/
%
%  BEWARE:
%
%    *  If a name contains a capital letter, which must be kept such,
%       use curly brackets ({T}hailand, {HIV}).
%
%  ===========================================================================

@InProceedings{Andre2014,
  Title                    = {Coordinated Multi-Robot Exploration: Out of the Box Packages for {ROS}},
  Author                   = {Andre, T. and Neuhold, D. and Bettstetter, C.},
  Booktitle                = {Proc. of IEEE GLOBECOM WiUAV Workshop},
  Year                     = {2014},
  Month                    = dec,
}

@misc{MapstitchROS,
  author = {Philipp M. Scholl},
  journal = {ROS Wiki},
  title = {Mapstitch},
  publisher = {Open Source Robotics Foundation},
  address = {Mountain View, CA},
  URL = {http://wiki.ros.org/mapstitch},
  year="2012",
}

@Article{Brown2006,
author="Brown, Matthew
and Lowe, David G.",
title="Automatic Panoramic Image Stitching using Invariant Features",
journal="International Journal of Computer Vision",
year="2006",
volume="74",
number="1",
pages="59--73",
abstract="This paper concerns the problem of fully automated panoramic image stitching. Though the 1D problem (single axis of rotation) is well studied, 2D or multi-row stitching is more difficult. Previous approaches have used human input or restrictions on the image sequence in order to establish matching images. In this work, we formulate stitching as a multi-image matching problem, and use invariant local features to find matches between all of the images. Because of this our method is insensitive to the ordering, orientation, scale and illumination of the input images. It is also insensitive to noise images that are not part of a panorama, and can recognise multiple panoramas in an unordered image dataset. In addition to providing more detail, this paper extends our previous work in the area (Brown and Lowe, 2003) by introducing gain compensation and automatic straightening steps.",
issn="1573-1405",
doi="10.1007/s11263-006-0002-3",
url="http://dx.doi.org/10.1007/s11263-006-0002-3"
}

@TechReport {Szeliski2004,
abstract     = {This tutorial reviews image alignment and image stitching algorithms. Image
                alignment (registration) algorithms can discover the large-scale (parametric)
                correspondence relationships among images with varying degrees of overlap. They
                are ideally suited for applications such as video stabilization, summarization,
                and the creation of large-scale panoramic photographs. Image stitching algorithms
                take the alignment estimates produced by such registration algorithms and blend
                the images in a seamless manner, taking care to deal with potential problems such
                as blurring or ghosting caused by parallax and scene movement as well as varying
                image exposures. This tutorial reviews the basic motion models underlying
                alignment and stitching algorithms, describes effective direct (pixel-based) and
                feature-based alignment algorithms, and describes blending algorithms used to
                produce seamless mosaics. It closes with a discussion of open research problems
                in the area.},
author       = {Richard Szeliski},
institution  = {Microsoft Research},
month        = {October},
number       = {MSR-TR-2004-92},
pages        = {89},
title        = {Image Alignment and Stitching: A Tutorial},
url          = {http://research.microsoft.com/apps/pubs/default.aspx?id=70092},
year         = {2004},
}

@Inproceedings {Shum1998,
abstract     = {This paper presents a new approach to computing depth maps from a large
                collection of images where the camera motion has been constrained to planar
                concentric circles. We resample the resulting collection of regular perspective
                images into a set of multiperspective panoramas, and then compute depth maps
                directly from these resampled images. Only a small number of multiperspective
                panoramas is needed to obtain a dense and accurate 3D reconstruction, since our
                panoramas sample uniformly in three dimensions: rotation angle, inverse radial
                distance, and vertical elevation. Using multiperspective panoramas avoids the
                limited overlap between the original input images that causes problems in
                conventional multi-baseline stereo. Our approach differs from stereo matching of
                panoramic images taken from different locations, where the epipolar constraints
                are sine curves. For our multiperspective panoramas, the epipolar geometry, to
                first order, consists of horizontal lines. Therefore, any traditional stereo
                algorithm can be applied to multiperspective panoramas without modification.
                Experimental results show that our approach generates good depth maps that can be
                used for image-based rendering tasks such as view interpolation and
                extrapolation.},
address      = {Bombay},
author       = {Heung-Yeung Shum and Richard Szeliski},
booktitle    = {Sixth International Conference on Computer Vision (ICCV'98)},
month        = {January},
pages        = {953-958},
publisher    = {IEEE Computer Society},
title        = {Construction and refinement of panoramic mosaics with global and local alignment},
url          = {http://research.microsoft.com/apps/pubs/default.aspx?id=75611},
year         = {1998},
}

@INPROCEEDINGS{Rublee2011,
author={E. Rublee and V. Rabaud and K. Konolige and G. Bradski},
booktitle={2011 International Conference on Computer Vision},
title={ORB: An efficient alternative to SIFT or SURF},
year={2011},
pages={2564-2571},
abstract={Feature matching is at the base of many computer vision problems, such as object recognition or structure from motion. Current methods rely on costly descriptors for detection and matching. In this paper, we propose a very fast binary descriptor based on BRIEF, called ORB, which is rotation invariant and resistant to noise. We demonstrate through experiments how ORB is at two orders of magnitude faster than SIFT, while performing as well in many situations. The efficiency is tested on several real-world applications, including object detection and patch-tracking on a smart phone.},
keywords={computer vision;image matching;object detection;object recognition;tracking;transforms;BRIEF;ORB;SIFT;SURF;binary descriptor;computer vision;feature matching;noise resistance;object detection;object recognition;patch-tracking;smart phone;Boats},
doi={10.1109/ICCV.2011.6126544},
ISSN={1550-5499},
month={Nov},
}

@Article{Xie2015,
author="Xie, Xin
and Xu, Yin
and Liu, Qing
and Hu, Fengping
and Cai, Tijian
and Jiang, Nan
and Xiong, Huandong",
title="A study on fast SIFT image mosaic algorithm based on compressed sensing and wavelet transform",
journal="Journal of Ambient Intelligence and Humanized Computing",
year="2015",
volume="6",
number="6",
pages="835--843",
abstract="Considering the disadvantages of massive calculation and slow speed of traditional Scale Invariant Feature Transform (SIFT) algorithm, we propose an improved image mosaic method which combines Wavelet Transform (WT) and Compressed Sensing (CS) algorithm. The method works as follows. Firstly, images are transformed with wavelet and compressed using compressed sensing technology. Then, image feature points are extracted in combination with SIFT algorithm. Finally, Sequential Similarity Detection Algorithm (SSDA) with adaptive threshold is used to fast search of image matching to find out an optimal stitching line, and a panoramic image is obtained. Experimental results demonstrate that the method realizes fast image matching, efficiently overcomes the shortcomings of heavy computation and low efficiency in the process of extracting image features, and guarantees matching accuracy and stitching efficiency, which meets the real-time requestments in machine vision system. This algorithm can be applied to image matching and stitching in the field of digital image security.",
issn="1868-5145",
doi="10.1007/s12652-015-0319-2",
url="http://dx.doi.org/10.1007/s12652-015-0319-2"
}

@misc{lowe2004method,
  title={Method and apparatus for identifying scale invariant features in an image and use of same for locating an object in an image},
  author={Lowe, D.G.},
  url={http://www.google.com/patents/US6711293},
  year={2004},
  month=mar # "~23",
  publisher={Google Patents},
  note={US Patent 6,711,293}
}

@INPROCEEDINGS{Alahi2012,
author={A. Alahi and R. Ortiz and P. Vandergheynst},
booktitle={Computer Vision and Pattern Recognition (CVPR), 2012 IEEE Conference on},
title={FREAK: Fast Retina Keypoint},
year={2012},
pages={510-517},
abstract={A large number of vision applications rely on matching keypoints across images. The last decade featured an arms-race towards faster and more robust keypoints and association algorithms: Scale Invariant Feature Transform (SIFT)[17], Speed-up Robust Feature (SURF)[4], and more recently Binary Robust Invariant Scalable Keypoints (BRISK)[I6] to name a few. These days, the deployment of vision algorithms on smart phones and embedded devices with low memory and computation complexity has even upped the ante: the goal is to make descriptors faster to compute, more compact while remaining robust to scale, rotation and noise. To best address the current requirements, we propose a novel keypoint descriptor inspired by the human visual system and more precisely the retina, coined Fast Retina Keypoint (FREAK). A cascade of binary strings is computed by efficiently comparing image intensities over a retinal sampling pattern. Our experiments show that FREAKs are in general faster to compute with lower memory load and also more robust than SIFT, SURF or BRISK. They are thus competitive alternatives to existing keypoints in particular for embedded applications.},
keywords={computational complexity;eye;image matching;smart phones;transforms;SIFT;SURF;association algorithm;binary robust invariant scalable keypoint;binary string;computation complexity;embedded application;embedded device;fast retina keypoint;human visual system;keypoint descriptor;keypoint matching;scale invariant feature transform;smart phone;speed-up robust feature;vision application;Detectors;Humans;Kernel;Noise;Retina;Robustness;Vectors},
doi={10.1109/CVPR.2012.6247715},
ISSN={1063-6919},
month={June},}

@article{alcantarilla2011fast,
  title={Fast explicit diffusion for accelerated features in nonlinear scale spaces},
  author={Alcantarilla, Pablo F and Solutions, TrueVision},
  journal={IEEE Trans. Patt. Anal. Mach. Intell},
  volume={34},
  number={7},
  pages={1281--1298},
  year={2011}
}

@article{calonder2010brief,
  title={Brief: Binary robust independent elementary features},
  author={Calonder, Michael and Lepetit, Vincent and Strecha, Christoph and Fua, Pascal},
  journal={Computer Vision--ECCV 2010},
  pages={778--792},
  year={2010},
  publisher={Springer}
}

@inproceedings{Muja2012,
  author    = {Marius Muja and David G. Lowe},
  title = {Fast Matching of Binary Features},
  booktitle = {Computer and Robot Vision {(CRV)}},
  year = {2012},
  pages = {404-410}
}

@article{fischler1981random,
  title={Random sample consensus: a paradigm for model fitting with applications to image analysis and automated cartography},
  author={Fischler, Martin A and Bolles, Robert C},
  journal={Communications of the ACM},
  volume={24},
  number={6},
  pages={381--395},
  year={1981},
  publisher={ACM}
}

@techreport{herrero2015multimaster,
  author = "S. Hernández and F. Herrero",
  title = "Multi-master {ROS} systems",
  type = "Technical Report",
  institution = "Institut de Robòtica i Informàtica Industrial, CSIC-UPC",
  number = "IRI-TR-15-01",
  year = {2015},
}

@misc{MultiMasterSIG,
  journal = {ROS Wiki},
  title = {Multimaster Special Interest Group},
  publisher = {Open Source Robotics Foundation},
  address = {Mountain View, CA},
  year = {2015-04-02},
  URL = {http://wiki.ros.org/sig/Multimaster},
}

@Inbook{Yan2014,
author="Yan, Zhi
and Fabresse, Luc
and Laval, Jannik
and Bouraqadi, Noury",
editor="Brugali, Davide
and Broenink, Jan F.
and Kroeger, Torsten
and MacDonald, Bruce A.",
chapter="Team Size Optimization for Multi-robot Exploration",
title="Simulation, Modeling, and Programming for Autonomous Robots: 4th International Conference, SIMPAR 2014, Bergamo, Italy, October 20-23, 2014. Proceedings",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="438--449",
isbn="978-3-319-11900-7",
doi="10.1007/978-3-319-11900-7_37",
url="http://dx.doi.org/10.1007/978-3-319-11900-7_37"
}

@INPROCEEDINGS{2013:RoboCup,
  author = {S. Kohlbrecher and J. Meyer and T. Graber and K. Petersen and O. von Stryk and U. Klingauf},
  title = {Hector open source modules for autonomous mapping and navigation with rescue robots},
  year = {2013},
  pages = {to appear},
  publisher = {Springer},
  series = {Lecture Notes in Artificial Intelligence (LNAI)},
  booktitle = {Proc. RoboCup Symposium 2013},
}

@misc{DuHadway2010,
  author = {Charles DuHadway},
  journal = {ROS Wiki},
  title = {explore},
  publisher = {Open Source Robotics Foundation},
  address = {Mountain View, CA},
  year = {2010-03-12},
  URL = {http://wiki.ros.org/explore},
}

@misc{Bovbel2010,
  author = {Paul Bovbel},
  journal = {ROS Wiki},
  title = {frontier\_exploration},
  publisher = {Open Source Robotics Foundation},
  address = {Mountain View, CA},
  year = {2015-04-07},
  URL = {http://wiki.ros.org/frontier_exploration},
}

@misc{Marthi2014,
  author = {Bhaskara Marthi},
  journal = {ROS Wiki},
  title = {occupancy\_grid\_utils},
  publisher = {Open Source Robotics Foundation},
  address = {Mountain View, CA},
  year = {2014-04-04},
  URL = {http://wiki.ros.org/occupancy_grid_utils},
}

@misc{Marder2016,
  author = {Marder-Eppstein, Eitan and Lu, David V. and Ferguson, Michael},
  journal = {ROS Wiki},
  title = {move\_base},
  publisher = {Open Source Robotics Foundation},
  address = {Mountain View, CA},
  year = {2016-03-03},
  URL = {http://wiki.ros.org/move_base},
}

@misc{GitHubOccGridUtils,
  author = {Clearpath Robotics},
  title = {occupancy\_grid\_utils},
  publisher = {GitHub},
  journal = {GitHub repository},
  year = {2016-04-26},
  URL = {https://github.com/clearpathrobotics/occupancy_grid_utils},
}

@misc{GitHubRoboRescue,
  author = {Horner, Jiri and Jelinek, Lukas},
  title = {p3dx\_robot},
  publisher = {GitHub},
  journal = {GitHub repository},
  year = {2016-05-01},
  URL = {https://github.com/hrnr/robo-rescue},
}

@article{Fallon2013,
author = {Fallon, Maurice and Johannsson, Hordur and Kaess, Michael and Leonard, John J},
title = {The MIT Stata Center dataset},
volume = {32},
number = {14},
pages = {1695-1699},
year = {2013},
doi = {10.1177/0278364913509035},
abstract ={This paper presents a large scale dataset of vision (stereo and RGB-D), laser and proprioceptive data collected over an extended duration by a Willow Garage PR2 robot in the 10 story MIT Stata Center. As of September 2012 the dataset comprises over 2.3 TB, 38 h and 42 km (the length of a marathon). The dataset is of particular interest to robotics and computer vision researchers interested in long-term autonomy. It is expected to be useful in a variety of research areas—robotic mapping (long-term, visual, RGB-D or laser), change detection in indoor environments, human pattern analysis, long-term path planning. For ease of use the original ROS ‘bag’ log files are provided and also a derivative version combining human readable data and imagery in standard formats. Of particular importance, this dataset also includes ground-truth position estimates of the robot at every instance (to typical accuracy of 2 cm) using as-built floor-plans—which were carefully extracted using our software tools. The provision of ground-truth for such a large dataset enables more meaningful comparison between algorithms than has previously been possible.},
URL = {http://ijr.sagepub.com/content/32/14/1695.abstract},
eprint = {http://ijr.sagepub.com/content/32/14/1695.full.pdf+html},
journal = {The International Journal of Robotics Research}
}

@INPROCEEDINGS{Lee2012,
author={H. C. Lee and Seung-Hwan Lee and Tae-Seok Lee and Doo-Jin Kim and B. H. Lee},
booktitle={Ubiquitous Robots and Ambient Intelligence (URAI), 2012 9th International Conference on},
title={A survey of map merging techniques for cooperative-SLAM},
year={2012},
pages={285-287},
abstract={This paper presents a survey of map merging techniques for cooperative-SLAM. The recently proposed map merging techniques are classified into two categories: direct map merging and indirect map merging. In each category, several techniques are briefly described. Then, their advantages and disadvantages are discussed in the context of accuracy and computation time. The description and discussion can contribute to realizing and improving cooperative-SLAM.},
keywords={SLAM (robots);mobile robots;multi-robot systems;cooperative-SLAM;direct map merging;indirect map merging;map merging techniques;simultaneous localization and mapping;Feature extraction;Hardware;Merging;Simultaneous localization and mapping;Visualization;Cooperative-SLAM;Distributed robot system;Map merging technique},
doi={10.1109/URAI.2012.6462995},
month={Nov},}

@INPROCEEDINGS{Zhou2006,
author={X. S. Zhou and S. I. Roumeliotis},
booktitle={2006 IEEE/RSJ International Conference on Intelligent Robots and Systems},
title={Multi-robot SLAM with Unknown Initial Correspondence: The Robot Rendezvous Case},
year={2006},
pages={1785-1792},
abstract={This paper presents a new approach to the multi-robot map-alignment problem that enables teams of robots to build joint maps without initial knowledge of their relative poses. The key contribution of this work is an optimal algorithm for merging (not necessarily overlapping) maps that are created by different robots independently. Relative pose measurements between pairs of robots are processed to compute the coordinate transformation between any two maps. Noise in the robot-to-robot observations, propagated through the map-alignment process, increases the error in the position estimates of the transformed landmarks, and reduces the overall accuracy of the merged map. When there is overlap between the two maps, landmarks that appear twice provide additional information, in the form of constraints, which increases the alignment accuracy. Landmark duplicates are identified through a fast nearest-neighbor matching algorithm. In order to reduce the computational complexity of this search process, a kd-tree is used to represent the landmarks in the original map. The criterion employed for matching any two landmarks is the Mahalanobis distance. As a means of validation, we present experimental results obtained from two robots mapping an area of 4,800 m2},
keywords={SLAM (robots);computational complexity;image matching;multi-robot systems;navigation;optimisation;robot vision;trees (mathematics);Mahalanobis distance;computational complexity;coordinate transformation;fast nearest-neighbor matching algorithm;joint maps;kd tree;map alignment problem;multi-robot SLAM;optimal map merging algorithm;position estimates;relative pose measurements;robot rendezvous case;robot-to-robot observation noise;unknown initial correspondence;Computational complexity;Computer science;Coordinate measuring machines;Intelligent robots;Maximum likelihood estimation;Merging;Noise reduction;Robot kinematics;Robot sensing systems;Simultaneous localization and mapping},
doi={10.1109/IROS.2006.282219},
ISSN={2153-0858},
month={Oct},}

@INPROCEEDINGS{Konolige2003,
author={K. Konolige and D. Fox and B. Limketkai and J. Ko and B. Stewart},
booktitle={Intelligent Robots and Systems, 2003. (IROS 2003). Proceedings. 2003 IEEE/RSJ International Conference on},
title={Map merging for distributed robot navigation},
year={2003},
volume={1},
pages={212-217 vol.1},
abstract={A set of robots mapping an area can potentially combine their information to produce a distributed map more efficiently than a single robot alone. We describe a general framework for distributed map building in the presence of uncertain communication. Within this framework, we then present a technical solution to the key decision problem of determining relative location within partial maps.},
keywords={image matching;mobile robots;multi-robot systems;navigation;distributed map building;distributed robot navigation;map merging;robot mapping;uncertain communication;Artificial intelligence;Centralized control;Communication system control;Intelligent robots;Merging;Navigation;Robot kinematics;Robot sensing systems;Robustness;Solids},
doi={10.1109/IROS.2003.1250630},
month={Oct},}

@Article{Carpin2008,
author="Carpin, Stefano",
title="Fast and accurate map merging for multi-robot systems",
journal="Autonomous Robots",
year="2008",
volume="25",
number="3",
pages="305--316",
abstract="We present a new algorithm for merging occupancy grid maps produced by multiple robots exploring the same environment. The algorithm produces a set of possible transformations needed to merge two maps, i.e translations and rotations. Each transformation is weighted, thus allowing to distinguish uncertain situations, and enabling to track multiple cases when ambiguities arise. Transformations are produced extracting some spectral information from the maps. The approach is deterministic, non-iterative, and fast. The algorithm has been tested on public available datasets, as well as on maps produced by two robots concurrently exploring both indoor and outdoor environments. Throughout the experimental validation stage the technique we propose consistently merged maps exhibiting very different characteristics.",
issn="1573-7527",
doi="10.1007/s10514-008-9097-4",
url="http://dx.doi.org/10.1007/s10514-008-9097-4"
}

@article{Lee2011,
author = { Heon-Cheol   Lee  and  Beom-Hee   Lee },
title = {Improved Feature Map Merging Using Virtual Supporting Lines for Multi-Robot Systems},
journal = {Advanced Robotics},
volume = {25},
number = {13-14},
pages = {1675-1696},
year = {2011},
doi = {10.1163/016918611X584631},

URL = {
        http://dx.doi.org/10.1163/016918611X584631

},
eprint = {
        http://dx.doi.org/10.1163/016918611X584631

}
,
    abstract = { This paper addresses the problem of feature map merging, which is one of the essential techniques for multi-robot systems. If inter-robot measurements are not available for feature map merging, the only way to obtain the map transformation matrix is feature map matching. However, the conventional feature map matching technique requires too much computation time because it has to be iteratively performed to compute the degree of the mismatch between multiple feature maps. This paper proposes a non-iterative feature map merging technique using virtual supporting lines (VSLs) which is also accurate and robust. The proposed technique extracts the spectral information of multiple feature maps using VSLs and obtains the map transformation matrix using the circular cross-correlation between the extracted spectral information of the multiple feature maps. The proposed technique was tested on feature maps produced by experiments with vision sensors, which was performed non-iteratively. In addition, it consistently showed a high acceptance index, which indicates the degree of accuracy for feature map merging. }
}

@INPROCEEDINGS{Wang2012,
author={K. Wang and S. Jia and Y. Li and X. Li and B. Guo},
booktitle={Information and Automation (ICIA), 2012 International Conference on},
title={Research on map merging for multi-robotic system based on RTM},
year={2012},
pages={156-161},
abstract={Multi-robotic system is widely used in exploring in large-scale unknown environment and performing the complex tasks. This paper presents a method of local map merging for Multi-robotic system using RTM as communication platform. We integrate Scale-Invariant Feature Transform (SIFT) feature matching information with iterative closest point (ICP) algorithm to realize the local map merging. We use the USARSim as simulation platform to realize topological map and map merging for the environment in which mobile robots moving using the proposed method. The paper details the architecture of the proposed method and gives some experiments to verify the effectiveness.},
keywords={SLAM (robots);control engineering computing;feature extraction;image matching;iterative methods;middleware;mobile robots;multi-robot systems;robot vision;transforms;ICP;RTM;SIFT;USARSim;iterative closest point algorithm;local map merging method;mobile robots;multirobotic system;robot technology middleware;scale-invariant feature transform feature matching information;topological map;Feature extraction;Merging;Mobile robots;Path planning;Robot sensing systems;Topology;ICP;Multi-robotic system;RTM;SIFT;map merging},
doi={10.1109/ICInfA.2012.6246800},
month={June},}