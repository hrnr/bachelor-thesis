\chapter{Merging algorithm}

In this chapter we present an merging algorithm based on computer vision techniques. This is not completely new even in ROS environment. First computer vision-based approach to merging was implemented in \cite{MapstitchROS}. This package's primary purpose was to stitch generated map to existing static map.

Although this package was not developed for map merging in multi-robot configuration, algorithm and its original implementation were used for coordinated multi-robot exploration solution presented in \cite{Andre2014}.

Due to its original purpose, mapstitch algorithm shows some limitations for multi-robot map merging setup. Originally it was designed for offline use \cite{Andre2014}. Also, it was designed for stitching two maps, one them being large reference map covering most of the environment. Although it is possible to incrementally merge maps from multiple robots with this algorithm, global map quality generally decreases with increasing number of robots. \cite{Andre2014}. Significant decrease in performance was observed for 4 robots\cite{Andre2014}.

\begin{algorithm}
    \caption{Mapstitch original algorithm}
    \label{alg:mapstitch}
    \begin{algorithmic}[1]
        \Procedure{StitchedMap}{$grid1, grid2$}
            \State detect Orb features
            \State match keypoints with Brute-Force matcher
            \State find matching point pairs with same distance in both images
            \State find homography (affine transform)
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

Algorithm~\ref{alg:mapstitch} shows original algorithm used in \cite{MapstitchROS}, version used in \cite{Andre2014} is only a slightly modified.

Although our algorithm also uses computer vision-based approach, proposed algorithm deals with most of the limitations of the original simple algorithm. Proposed algorithm is designed to work with unlimited number of grids, so it requires no additional need for iterative merging. More importantly, by design, algorithm can determine optimal order of individual pairwise merges. I assume this might be the main reason for decrease in performance in $4$-robot setup observed by\cite{Andre2014}. Also proposed algorithm deals with other problems arising for general $n$-map merge problem such as situations when it is not possible to merge some of the maps because transformation to others could not be reliably estimated, cases where map transformation can be estimated from more sources (multiple neighbours) etc.

\section{Stitching pipeline} % (fold)
\label{sec:stitching_pipeline}

As discussed in chapter \#reference here\# our algorithm is inspired by image stitching algorithms. Stitching algorithms are well-understood and implementations are broadly available. General concept of multi-step stitching pipeline is described in \cite{Brown2006}. Stitching pipeline is also well established code in OpenCV, mostly based on \cite{Brown2006}, along with \cite{Szeliski2004} \cite{Shum1998} and others. Figure~\ref{fig:opencv} highlights processing steps in stitching as implemented in OpenCV.

\begin{figure}
	\centering
	\includegraphics[width=4.33in]{../img/StitchingPipeline.jpg}
	\caption{OpenCV Stitching pipeline.}
	\label{fig:opencv}
\end{figure}

Our algorithm will solve the registration part of stitching according to figure~\ref{fig:opencv}. As compositing part of stitching is relatively simple for occupancy grids compared to images from camera, this solves the main problem of acquiring transformation between robots individual frames and bridging the problem of merging maps with known initial positions and unknown initial positions.

ROS node for map merging described in \#reference here\# implements also compositing part of the pipeline, which is simple when transformation is estimated with high precision.

For description of the algorithm we will assume to have maps represented as occupancy grids, with each cell containing value in range $[0,100]$ indicating probability that there is obstacle in the cell and $-1$ for indicating unknown probability. This representation is basically greyscale image, hence using image processing algorithms seems natural.

We will with occupancy grids as greyscale images through algorithm~\ref{alg:estimategridtrasform}. Values in the image are exactly the same is in occupancy grids, without any mapping. This means images are be basically only $7$-bit depth.

Algorithm~\ref{alg:estimategridtrasform} offers overview of the proposed algorithm, detailed description will be provided in following sections.

\begin{algorithm}
    \caption{Proposed algorithm for estimating transform between multiple occupancy grids}
    \label{alg:estimategridtrasform}
    \begin{algorithmic}[1]
        \Procedure{estimateGridTransform}{$grids$}
            \State detect Orb features (keypoints) for each grid
            \ForAll{pair of grids} \Comment{we will compute transformation between each image along with confidence}
            	\State match features
            	\State $n \gets \text{number of matches}$
            	\If{$n \le $}
            		\State confidence $\gets 0$
            	\Else
            		\State find restricted affine transformation for keypoints using RANSAC
            		\State $\vartheta \gets \text{number of inliers in RANSAC}$
            		\If{transformation found}
            			\State confidence $\gets \frac{\vartheta}{8 + 0.3 \cdot n}$
            		\Else
            			\State confidence $\gets 0$
            		\EndIf
            	\EndIf
            \EndFor
            \State matches $\gets (i,j)$ for matches with confidence $\ge 1.0$
            \State $g \gets (grids, matches)$
            \State $h \gets$ largest connected component in $g$
            \State $t \gets$ maximum spanning tree in $h$
            \State walk $t$ and compute transformations to global reference frame
        \EndProcedure
    \end{algorithmic}
\end{algorithm}

% section stitching_pipeline (end)

\section{Feature detection} % (fold)
\label{sec:feature_detection}

Stitching pipeline proposed in \cite{Brown2006} is using SIFT features. SIFT features have been used with success for stitching in many applications. Some of the recent approaches to stitching, improving traditional SIFT-based algorithm, are also building on top of SIFT features \cite{Xie2015}. SIFT features are patented in the US \cite{lowe2004method}, limiting its use.

I have decided to use ORB as feature detector a descriptor described in \cite{Rublee2011}. ORB algorithm is patent-free, and available in OpenCV. ORB features has been already used with occupancy grid images \cite{MapstitchROS} \cite{Andre2014}.

Other alternatives for feature detection and feature description has not been tested yet. Performance of other detectors for map merging and effect of choose of detector to overall merging performance remains to be evaluated. Some feature detectors and descriptors promising good performance are \cite{Alahi2012} \cite{alcantarilla2011fast} \cite{calonder2010brief}.

For image stitching, images are usually downscaled for further processing as seen is figure~\ref{fig:opencv}. Feature extraction and feature matching on smaller images is considerably faster and final performance is acceptable. We don't propose any such down scaling for occupancy grids. Occupancy grids acquired from mapping are usually smaller than multi-megapixel images from camera, so stitching time is reasonable even for full-scale grids. Also occupancy grids have usually much smaller number of features than photos making stitching harder and less precise.

During online merging we can run stitching with low frequency even if higher map update frequencies are required by simply using previously estimated transform between grids. This further reduces cost of estimation over time. Since transformation between grids is fixed in most cases (when SLAM algorithm work reasonably well), depending only on starting points of robots, this approach does not reduce map quality considerably.

In most tested scenarios estimated transformation change only during initial phase. After there is enough overlapping regions in the map, such that transformation can be estimated with enough precision, transformation estimated with stitching algorithm remains stable over time. This property allows to run re-estimation with low frequencies.

% section feature_detection (end)

\section{Pairwise matching} % (fold)
\label{sec:pairwise_matching}

Pairwise matching is the most resource demanding part of the algorithm. We do matching for all $\bigO(n^2)$ pairs of grids. For panorama images it is possible to push this down to $\bigO(n)$ matching by expecting photos to be taken in ordered sequence. We can then match image only $k$ neighbours (for small $k$) in sequence, because neighbours are expected to have overlapping area.

For occupancy grids in multi-robot mapping scenario it is impractical to assume any

\begin{figure}
    \centering
    \includegraphics[width=\textwidth]{../img/matches.pdf}
    \caption{Graph showing matches between occupancy grids during map merging. This graph was acquired for maps from MIT dataset, see chapter \#reference here\#. Grids without any matches are omitted. Legend: $Nm$ number of matches, $Ni$ number of inliers from RANSAC, $C$ confidence.}
    \label{fig:matches}
\end{figure}

% section pairwise_matching (end)